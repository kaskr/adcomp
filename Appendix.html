<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>TMB Documentation: Appendix</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">TMB Documentation
   &#160;<span id="projectnumber">v1.9.1</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Appendix </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>Notation</h2>
<p>We use the following notation</p>
<table class="doxtable">
<tr>
<th>Notation </th><th>Explanation  </th></tr>
<tr>
<td>\(u\) </td><td>The random effects vector </td></tr>
<tr>
<td>\(\theta\) </td><td>Parameter vector (first part) </td></tr>
<tr>
<td>\(\beta\) </td><td>Parameter vector (second part) </td></tr>
<tr>
<td>\(f(u,\beta,\theta)\) </td><td>Joint negative log likelihood </td></tr>
<tr>
<td>\(x\) </td><td>Data </td></tr>
<tr>
<td>\(E(u|x)\) </td><td>Conditional expectation of random effect given data </td></tr>
<tr>
<td>\(\hat u\) </td><td>The posterior mode \(\arg \min_{u} f(u,\beta,\theta)\) </td></tr>
</table>
<h2>Profiling the inner problem</h2>
<p>This section describes the underlying theory of the argument <code>profile</code> to <code>MakeADFun</code> intended to speedup and robustify linear mixed effect models with a large number of fixed effects. With a few common model properties (Assumption 1 and 2 below), which must be checked by the user, one can apply the <code>profile</code> argument to move outer parameters to the inner problem without affecting the model result.</p>
<p><b>Theorem 1 (Profiling inner problem)</b> Assume that for any \(\beta\) and \(\theta\)</p>
<ul>
<li><b>Assumption 1</b> The partial derivative \(\partial_{\beta} f(u,\beta,\theta)\) is a linear function of u.</li>
<li><b>Assumption 2</b> The posterior mean is equal to the posterior mode: \(E(u|x)=\hat u\)</li>
</ul>
<p>Then the MLE</p>
<p class="formulaDsp">
\[\hat \beta := \arg \max_{\beta} \left( \int \exp(-f(u,\beta,\theta)) \: du \right) \]
</p>
<p>is a solution to the augmented system</p>
<p class="formulaDsp">
\[ \begin{split} \partial_{u} f(u,\beta,\theta) &amp;= 0 \\ \partial_{\beta} f(u,\beta,\theta) &amp;= 0 \end{split} \]
</p>
<p>The augmented system defines \(\hat \beta\) implicitly as function of the posterior mode \(\hat u\).</p>
<p><em>Proof</em></p>
<p>Differentiation of the negative log marginal likelihood gives</p>
<p class="formulaDsp">
\[ \begin{split} \partial_{\beta} \left( -\log \int \exp(-f(u,\beta,\theta)) \: du \right) &amp;= E(\partial_{\beta}f(u,\beta,\theta) |x) \\ &amp;= \partial_{\beta} f(u,\beta,\theta)_{|u=\hat u(\beta,\theta)} \end{split} \]
</p>
<p>where the first equality holds in general and the second equality follows from assumptions (1) and (2).</p>
<p>\(\square\)</p>
<h3>Example</h3>
<p>The standard situation for which <b>assumption 1</b> holds is when the \(\beta\)s are the linear fixed effects of a mixed model. In this case the joint negative log density takes the form </p><p class="formulaDsp">
\[ f(u,\beta,\theta) = \frac{1}{2}(u-A\beta)&#39;\Sigma_{\theta}^{-1}(u-A\beta) + ... \]
</p>
<p> for some design matrix \(A\) where ' \(...\) ' does not depend on \(\beta\). The derivative </p><p class="formulaDsp">
\[ \partial_{\beta} f(u,\beta,\theta) = A&#39;\Sigma_{\theta}^{-1}(u-A\beta) \]
</p>
<p> is thus a linear function of the random effect \(u\).</p>
<p>In general <b>assumption 2</b> holds exact for models with a symmetric (e.g. Gaussian) posterior distribution.</p>
<h2>Theory underlying sdreport</h2>
<p>This section supplements the documentation of <code>?sdreport</code> by adding some missing details.</p>
<p>As previously, we consider a general latent variable model with parameter vector \(\theta\), random effect vector \(u\) and observation vector \(x\). The TMB estimation procedure works as follows:</p>
<ol type="1">
<li>The MLE \(\hat\theta=\hat\theta(x)\) is calculated and used as estimator of \(\theta\).</li>
<li>Denote by \(\hat u(\theta,x)\) the random effect mode depending on \(\theta\) and \(x\). Now, <em>plug in</em> the MLE, and we get our estimator \(\hat u\left(\hat\theta(x),x\right)\) of \(u\).</li>
</ol>
<p>In general, we assume that \(\hat\theta\) is a consistent estimator of \(\theta\). However, we do not in general require \(\hat u\) to be consistent for \(u\). The purpose of sdreport is, for a given realization of the pair \((u,x)\), to quantify the joint uncertainty of \((\hat u,\hat\theta)\) as estimator of \((u,\theta)\). That is, we are interested in the variance matrix of the difference</p>
<p>[D:={pmatrix} u((x),x) - u\ (x) - {pmatrix}]</p>
<p>An important point of the uncertainty quantification is to account for plugging in \(\hat\theta\) rather than using the true \(\theta\).</p>
<p>We calculate the variance using the standard formula:</p>
<p>[V[D]=E(V(D|x))+V(E(D|x))]</p>
<p>Consider \(D\) conditionally on \(x\). The second component does not depend on \(u\) and \(\hat u\) is constant given \(x\):</p>
<p>[V[D|x]={pmatrix}V[u|x] &amp; 0 \ 0 &amp; 0 {pmatrix}]</p>
<p>It follows that</p>
<p>[E(V[D|x])={pmatrix}E(V[u|x]) &amp; 0 \ 0 &amp; 0 {pmatrix}]</p>
<p>As central estimator of \(E(V[u|x])\) we use \(V[u|x]\) which is approximated by the inverse random effect Hessian \(H_{uu}^{-1}\) based on the assumption that \(u|x\) is well approximated by a Gaussian distribution (a reasonable assumption given that we are using the Laplace approximation). This explains the first term of variance formula in <code>?sdreport</code>:</p>
<p>[E(V[D|x])  {pmatrix} H_{uu}^{-1} &amp; 0 \ 0 &amp; 0 {pmatrix}]</p>
<p>Likewise,</p>
<p>[E[D|x]={pmatrix} u((x),x) - E(u|x)\ (x) - {pmatrix}]</p>
<p>Again, asuming a Gaussian approximation of \(u|x\), it follows that \(E(u|x) \approx \hat u(\theta,x)\):</p>
<p>[E[D|x]={pmatrix} u((x),x) -  u(,x)\ (x) - {pmatrix}]</p>
<p>We approximate the expectation using linerization of \(\theta \rightarrow \hat u(\theta,x)\) around \(\hat\theta(x)\)</p>
<p>[E[D|x]=J_x  ((x) - )]</p>
<p>We now have the second term of the variance formula in <code>?sdreport</code>:</p>
<p>[V(E[D|x])  J_x V((x)) J_x']</p>
<p>This term becomes negligible if the amount of data is high because of the assumed asymptotic consistency of \(\hat\theta\). </p>
</div></div><!-- contents -->
License: <a href="https://gnu.org/licenses/old-licenses/gpl-2.0.txt">GPL v2</a>
