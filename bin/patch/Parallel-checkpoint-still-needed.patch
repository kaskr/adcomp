From 1e4f0c7bddc6248123d221e659e631e6ce62b343 Mon Sep 17 00:00:00 2001
From: Kasper Kristensen <kaskr@dtu.dk>
Date: Wed, 22 Nov 2017 16:10:25 +0100
Subject: [PATCH 4/6] Parallel checkpoint (still needed ?)

---
 TMB/inst/include/cppad/core/checkpoint.hpp | 136 ++++++++++++++++-------------
 1 file changed, 75 insertions(+), 61 deletions(-)

diff --git a/TMB/inst/include/cppad/core/checkpoint.hpp b/TMB/inst/include/cppad/core/checkpoint.hpp
index d5e7467..06039e1 100644
--- a/TMB/inst/include/cppad/core/checkpoint.hpp
+++ b/TMB/inst/include/cppad/core/checkpoint.hpp
@@ -243,6 +243,15 @@ It returns true if it succeeds and false if it fails.
 
 $end
 */
+
+#ifdef _OPENMP
+#define NTHREADS omp_get_max_threads()
+#define THREAD omp_get_thread_num()
+#else
+#define NTHREADS 1
+#define THREAD 0
+#endif
+
 template <class Base>
 class checkpoint : public atomic_base<Base> {
 // ---------------------------------------------------------------------------
@@ -251,7 +260,7 @@ private:
 	typedef typename atomic_base<Base>::option_enum option_enum;
 	//
 	/// AD function corresponding to this checkpoint object
-	ADFun<Base> f_;
+	vector<ADFun<Base> > f_;
 	//
 	/// sparsity for entire Jacobian f(x)^{(1)} does not change so can cache it
 	local::sparse_list         jac_sparse_set_;
@@ -269,8 +278,8 @@ private:
 	{	CPPAD_ASSERT_UNKNOWN( jac_sparse_set_.n_set() == 0 );
 		bool transpose  = false;
 		bool dependency = true;
-		size_t n = f_.Domain();
-		size_t m = f_.Range();
+		size_t n = f_[THREAD].Domain();
+		size_t m = f_[THREAD].Range();
 		// Use the choice for forward / reverse that results in smaller
 		// size for the sparsity pattern of all variables in the tape.
 		if( n <= m )
@@ -278,30 +287,30 @@ private:
 			identity.resize(n, n);
 			for(size_t j = 0; j < n; j++)
 				identity.add_element(j, j);
-			f_.ForSparseJacCheckpoint(
+			f_[THREAD].ForSparseJacCheckpoint(
 				n, identity, transpose, dependency, jac_sparse_set_
 			);
-			f_.size_forward_set(0);
+			f_[THREAD].size_forward_set(0);
 		}
 		else
 		{	local::sparse_list identity;
 			identity.resize(m, m);
 			for(size_t i = 0; i < m; i++)
 				identity.add_element(i, i);
-			f_.RevSparseJacCheckpoint(
+			f_[THREAD].RevSparseJacCheckpoint(
 				m, identity, transpose, dependency, jac_sparse_set_
 			);
 		}
-		CPPAD_ASSERT_UNKNOWN( f_.size_forward_set() == 0 );
-		CPPAD_ASSERT_UNKNOWN( f_.size_forward_bool() == 0 );
+		CPPAD_ASSERT_UNKNOWN( f_[THREAD].size_forward_set() == 0 );
+		CPPAD_ASSERT_UNKNOWN( f_[THREAD].size_forward_bool() == 0 );
 	}
 	/// set jac_sparse_bool_
 	void set_jac_sparse_bool(void)
 	{	CPPAD_ASSERT_UNKNOWN( jac_sparse_bool_.size() == 0 );
 		bool transpose  = false;
 		bool dependency = true;
-		size_t n = f_.Domain();
-		size_t m = f_.Range();
+		size_t n = f_[THREAD].Domain();
+		size_t m = f_[THREAD].Range();
 		// Use the choice for forward / reverse that results in smaller
 		// size for the sparsity pattern of all variables in the tape.
 		if( n <= m )
@@ -310,10 +319,10 @@ private:
 			{	for(size_t i = 0; i < n; i++)
 					identity[ i * n + j ] = (i == j);
 			}
-			jac_sparse_bool_ = f_.ForSparseJac(
+			jac_sparse_bool_ = f_[THREAD].ForSparseJac(
 				n, identity, transpose, dependency
 			);
-			f_.size_forward_bool(0);
+			f_[THREAD].size_forward_bool(0);
 		}
 		else
 		{	vectorBool identity(m * m);
@@ -321,19 +330,19 @@ private:
 			{	for(size_t i = 0; i < m; i++)
 					identity[ i * m + j ] = (i == j);
 			}
-			jac_sparse_bool_ = f_.RevSparseJac(
+			jac_sparse_bool_ = f_[THREAD].RevSparseJac(
 				m, identity, transpose, dependency
 			);
 		}
-		CPPAD_ASSERT_UNKNOWN( f_.size_forward_bool() == 0 );
-		CPPAD_ASSERT_UNKNOWN( f_.size_forward_set() == 0 );
+		CPPAD_ASSERT_UNKNOWN( f_[THREAD].size_forward_bool() == 0 );
+		CPPAD_ASSERT_UNKNOWN( f_[THREAD].size_forward_set() == 0 );
 	}
 	// ------------------------------------------------------------------------
 	/// set hes_sparse_set_
 	void set_hes_sparse_set(void)
 	{	CPPAD_ASSERT_UNKNOWN( hes_sparse_set_.n_set() == 0 );
-		size_t n = f_.Domain();
-		size_t m = f_.Range();
+		size_t n = f_[THREAD].Domain();
+		size_t m = f_[THREAD].Range();
 		//
 		// set version of sparsity for vector of all ones
 		vector<bool> all_one(m);
@@ -349,23 +358,23 @@ private:
 		// compute sparsity pattern for H(x) = sum_i f_i(x)^{(2)}
 		bool transpose  = false;
 		bool dependency = false;
-		f_.ForSparseJacCheckpoint(
+		f_[THREAD].ForSparseJacCheckpoint(
 			n, identity, transpose, dependency, jac_sparse_set_
 		);
-		f_.RevSparseHesCheckpoint(
+		f_[THREAD].RevSparseHesCheckpoint(
 			n, all_one, transpose, hes_sparse_set_
 		);
 		CPPAD_ASSERT_UNKNOWN( hes_sparse_set_.n_set() == n );
 		CPPAD_ASSERT_UNKNOWN( hes_sparse_set_.end()   == n );
 		//
 		// drop the forward sparsity results from f_
-		f_.size_forward_set(0);
+		f_[THREAD].size_forward_set(0);
 	}
 	/// set hes_sparse_bool_
 	void set_hes_sparse_bool(void)
 	{	CPPAD_ASSERT_UNKNOWN( hes_sparse_bool_.size() == 0 );
-		size_t n = f_.Domain();
-		size_t m = f_.Range();
+		size_t n = f_[THREAD].Domain();
+		size_t m = f_[THREAD].Range();
 		//
 		// set version of sparsity for vector of all ones
 		vectorBool all_one(m);
@@ -382,14 +391,14 @@ private:
 		// compute sparsity pattern for H(x) = sum_i f_i(x)^{(2)}
 		bool transpose  = false;
 		bool dependency = false;
-		f_.ForSparseJac(n, identity, transpose, dependency);
-		hes_sparse_bool_ = f_.RevSparseHes(n, all_one, transpose);
+		f_[THREAD].ForSparseJac(n, identity, transpose, dependency);
+		hes_sparse_bool_ = f_[THREAD].RevSparseHes(n, all_one, transpose);
 		CPPAD_ASSERT_UNKNOWN( hes_sparse_bool_.size() == n * n );
 		//
 		// drop the forward sparsity results from f_
-		f_.size_forward_bool(0);
-		CPPAD_ASSERT_UNKNOWN( f_.size_forward_bool() == 0 );
-		CPPAD_ASSERT_UNKNOWN( f_.size_forward_set() == 0 );
+		f_[THREAD].size_forward_bool(0);
+		CPPAD_ASSERT_UNKNOWN( f_[THREAD].size_forward_bool() == 0 );
+		CPPAD_ASSERT_UNKNOWN( f_[THREAD].size_forward_set() == 0 );
 	}
 	// ------------------------------------------------------------------------
 	/*!
@@ -404,8 +413,8 @@ private:
 		      sparsity_type&                    s  ,
 		const vector<Base>&                     x  )
 	{	// during user sparsity calculations
-		size_t m = f_.Range();
-		size_t n = f_.Domain();
+		size_t m = f_[THREAD].Range();
+		size_t n = f_[THREAD].Domain();
 		if( jac_sparse_bool_.size() == 0 )
 			set_jac_sparse_bool();
 		if( jac_sparse_set_.n_set() != 0 )
@@ -449,8 +458,8 @@ private:
 		      sparsity_type&                    st ,
 		const vector<Base>&                     x  )
 	{	// during user sparsity calculations
-		size_t m = f_.Range();
-		size_t n = f_.Domain();
+		size_t m = f_[THREAD].Range();
+		size_t n = f_[THREAD].Domain();
 		if( jac_sparse_bool_.size() == 0 )
 			set_jac_sparse_bool();
 		if( jac_sparse_set_.n_set() != 0 )
@@ -494,9 +503,9 @@ private:
 		const sparsity_type&                    u  ,
 		      sparsity_type&                    v  ,
 		const vector<Base>&                     x  )
-	{	size_t n = f_.Domain();
+	{	size_t n = f_[THREAD].Domain();
 # ifndef NDEBUG
-		size_t m = f_.Range();
+		size_t m = f_[THREAD].Range();
 # endif
 		CPPAD_ASSERT_UNKNOWN( vx.size() == n );
 		CPPAD_ASSERT_UNKNOWN(  s.size() == m );
@@ -517,7 +526,7 @@ private:
 
 
 		// compute sparsity pattern for T(x) = S(x) * f'(x)
-		t = f_.RevSparseJac(1, s);
+		t = f_[THREAD].RevSparseJac(1, s);
 # ifndef NDEBUG
 		for(size_t j = 0; j < n; j++)
 			CPPAD_ASSERT_UNKNOWN( vx[j] || ! t[j] )
@@ -530,7 +539,7 @@ private:
 		// compute sparsity pattern for A(x) = f'(x)^T * U(x)
 		bool transpose = true;
 		sparsity_type a(n * q);
-		a = f_.RevSparseJac(q, u, transpose);
+		a = f_[THREAD].RevSparseJac(q, u, transpose);
 
 		// Need sparsity pattern for H(x) = (S(x) * f(x))''(x) * R,
 		// but use less efficient sparsity for  f(x)''(x) * R so that
@@ -597,7 +606,7 @@ l	should the operation sequence corresponding to the algo be optimized.
 		bool                           optimize = true
 	) : atomic_base<Base>(name, sparsity)
 	{	CheckSimpleVector< CppAD::AD<Base> , ADVector>();
-
+		f_.resize(NTHREADS);
 		// make a copy of ax because Independent modifies AD information
 		ADVector x_tmp(ax);
 		// delcare x_tmp as the independent variables
@@ -605,25 +614,27 @@ l	should the operation sequence corresponding to the algo be optimized.
 		// record mapping from x_tmp to ay
 		algo(x_tmp, ay);
 		// create function f_ : x -> y
-		f_.Dependent(ay);
+		f_[0].Dependent(ay);
 		if( optimize )
 		{	// suppress checking for nan in f_ results
 			// (see optimize documentation for atomic functions)
-			f_.check_for_nan(false);
+			f_[0].check_for_nan(false);
 			//
 			// now optimize
-			f_.optimize();
+			f_[0].optimize();
 		}
 		// now disable checking of comparison operations
 		// 2DO: add a debugging mode that checks for changes and aborts
-		f_.compare_change_count(0);
+		f_[0].compare_change_count(0);
+		// Copy for other threads
+		for(size_t i = 1; i < NTHREADS; i++) f_[i] = f_[0];
 	}
 	// ------------------------------------------------------------------------
 	/*!
 	Implement the user call to <tt>atom_fun.size_var()</tt>.
 	*/
 	size_t size_var(void)
-	{	return f_.size_var(); }
+	{	return f_[THREAD].size_var(); }
 	// ------------------------------------------------------------------------
 	/*!
 	Implement the user call to <tt>atom_fun(ax, ay)</tt>.
@@ -663,10 +674,10 @@ l	should the operation sequence corresponding to the algo be optimized.
 		      vector<bool>&      vy ,
 		const vector<Base>&      tx ,
 		      vector<Base>&      ty )
-	{	size_t n = f_.Domain();
-		size_t m = f_.Range();
+	{	size_t n = f_[THREAD].Domain();
+		size_t m = f_[THREAD].Range();
 		//
-		CPPAD_ASSERT_UNKNOWN( f_.size_var() > 0 );
+		CPPAD_ASSERT_UNKNOWN( f_[THREAD].size_var() > 0 );
 		CPPAD_ASSERT_UNKNOWN( tx.size() % (q+1) == 0 );
 		CPPAD_ASSERT_UNKNOWN( ty.size() % (q+1) == 0 );
 		CPPAD_ASSERT_UNKNOWN( n == tx.size() / (q+1) );
@@ -727,14 +738,14 @@ l	should the operation sequence corresponding to the algo be optimized.
 			}
 		}
 		// compute forward results for orders zero through q
-		ty = f_.Forward(q, tx);
+		ty = f_[THREAD].Forward(q, tx);
 
 		// no longer need the Taylor coefficients in f_
 		// (have to reconstruct them every time)
 		// Hold onto sparsity pattern because it is always good.
 		size_t c = 0;
 		size_t r = 0;
-		f_.capacity_order(c, r);
+		f_[THREAD].capacity_order(c, r);
 		return ok;
 	}
 	// ------------------------------------------------------------------------
@@ -751,12 +762,12 @@ l	should the operation sequence corresponding to the algo be optimized.
 		const vector<Base>&       py )
 	{
 # ifndef NDEBUG
-		size_t n = f_.Domain();
-		size_t m = f_.Range();
+		size_t n = f_[THREAD].Domain();
+		size_t m = f_[THREAD].Range();
 # endif
 		CPPAD_ASSERT_UNKNOWN( n == tx.size() / (q+1) );
 		CPPAD_ASSERT_UNKNOWN( m == ty.size() / (q+1) );
-		CPPAD_ASSERT_UNKNOWN( f_.size_var() > 0 );
+		CPPAD_ASSERT_UNKNOWN( f_[THREAD].size_var() > 0 );
 		CPPAD_ASSERT_UNKNOWN( tx.size() % (q+1) == 0 );
 		CPPAD_ASSERT_UNKNOWN( ty.size() % (q+1) == 0 );
 		bool ok  = true;
@@ -764,14 +775,14 @@ l	should the operation sequence corresponding to the algo be optimized.
 		// put proper forward mode coefficients in f_
 # ifdef NDEBUG
 		// compute forward results for orders zero through q
-		f_.Forward(q, tx);
+		f_[THREAD].Forward(q, tx);
 # else
 		CPPAD_ASSERT_UNKNOWN( px.size() == n * (q+1) );
 		CPPAD_ASSERT_UNKNOWN( py.size() == m * (q+1) );
 		size_t i, j, k;
 		//
 		// compute forward results for orders zero through q
-		vector<Base> check_ty = f_.Forward(q, tx);
+		vector<Base> check_ty = f_[THREAD].Forward(q, tx);
 		for(i = 0; i < m; i++)
 		{	for(k = 0; k <= q; k++)
 			{	j = i * (q+1) + k;
@@ -780,13 +791,13 @@ l	should the operation sequence corresponding to the algo be optimized.
 		}
 # endif
 		// now can run reverse mode
-		px = f_.Reverse(q+1, py);
+		px = f_[THREAD].Reverse(q+1, py);
 
 		// no longer need the Taylor coefficients in f_
 		// (have to reconstruct them every time)
 		size_t c = 0;
 		size_t r = 0;
-		f_.capacity_order(c, r);
+		f_[THREAD].capacity_order(c, r);
 		return ok;
 	}
 	// ------------------------------------------------------------------------
@@ -825,8 +836,8 @@ l	should the operation sequence corresponding to the algo be optimized.
 		      vector< std::set<size_t> >&       s  ,
 		const vector<Base>&                     x  )
 	{	// during user sparsity calculations
-		size_t m = f_.Range();
-		size_t n = f_.Domain();
+		size_t m = f_[THREAD].Range();
+		size_t n = f_[THREAD].Domain();
 		if( jac_sparse_bool_.size() != 0 )
 			jac_sparse_bool_.clear();
 		if( jac_sparse_set_.n_set() == 0 )
@@ -896,8 +907,8 @@ l	should the operation sequence corresponding to the algo be optimized.
 		      vector< std::set<size_t> >&       st ,
 		const vector<Base>&                     x  )
 	{	// during user sparsity calculations
-		size_t m = f_.Range();
-		size_t n = f_.Domain();
+		size_t m = f_[THREAD].Range();
+		size_t n = f_[THREAD].Domain();
 		if( jac_sparse_bool_.size() != 0 )
 			jac_sparse_bool_.clear();
 		if( jac_sparse_set_.n_set() == 0 )
@@ -984,9 +995,9 @@ l	should the operation sequence corresponding to the algo be optimized.
 		const vector< std::set<size_t> >&       u  ,
 		      vector< std::set<size_t> >&       v  ,
 		const vector<Base>&                     x  )
-	{	size_t n = f_.Domain();
+	{	size_t n = f_[THREAD].Domain();
 # ifndef NDEBUG
-		size_t m = f_.Range();
+		size_t m = f_[THREAD].Range();
 # endif
 		CPPAD_ASSERT_UNKNOWN( vx.size() == n );
 		CPPAD_ASSERT_UNKNOWN(  s.size() == m );
@@ -1007,7 +1018,7 @@ l	should the operation sequence corresponding to the algo be optimized.
 		CPPAD_ASSERT_UNKNOWN( hes_sparse_set_.end()   == n );
 
 		// compute sparsity pattern for T(x) = S(x) * f'(x)
-		t = f_.RevSparseJac(1, s);
+		t = f_[THREAD].RevSparseJac(1, s);
 # ifndef NDEBUG
 		for(size_t j = 0; j < n; j++)
 			CPPAD_ASSERT_UNKNOWN( vx[j] || ! t[j] )
@@ -1021,7 +1032,7 @@ l	should the operation sequence corresponding to the algo be optimized.
 		// 2DO: change a to use INTERNAL_SPARSE_SET
 		bool transpose = true;
 		vector< std::set<size_t> > a(n);
-		a = f_.RevSparseJac(q, u, transpose);
+		a = f_[THREAD].RevSparseJac(q, u, transpose);
 
 		// Need sparsity pattern for H(x) = (S(x) * f(x))''(x) * R,
 		// but use less efficient sparsity for  f(x)''(x) * R so that
@@ -1056,3 +1067,6 @@ l	should the operation sequence corresponding to the algo be optimized.
 
 } // END_CPPAD_NAMESPACE
 # endif
+
+#undef NTHREADS
+#undef THREAD
-- 
2.7.4

